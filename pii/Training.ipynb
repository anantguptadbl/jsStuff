{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow\n",
    "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding, Flatten, Concatenate, Dense, Input, LSTM, Embedding, Dropout, Activation, GRU, Flatten\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################\n",
    "### TRIAL 1\n",
    "################################################\n",
    "\n",
    "# Config\n",
    "#tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "# We will create our own dataset\n",
    "data = ['I would like to close my account. My account number is 000345-9876',\n",
    "       'Hello I would like to close my account',\n",
    "       'My account needs to be closed',\n",
    "       'I need to close my account',\n",
    "       'Can you close my account. My SSN is 345-456-88976',\n",
    "       'My name is Anant Gupta and I would like to close my account',\n",
    "       'I need to open a new account. My SSN is 607-089-4563',\n",
    "       'I need to open a new account. Do you need my SSN'\n",
    "       ]\n",
    "labels = [1,0,0,0,1,0,1,0]\n",
    "\n",
    "# We will now be converting SSN numbers to SSSSS, ACCOUNT numbers to XXXXX\n",
    "import re\n",
    "data = [re.sub(r\"\\d\\d\\d-\\d\\d\\d-\\d\\d\\d\\d\", \"SSSSS\", x) for x in data]\n",
    "data = [re.sub(r\"\\d\\d\\d\\d\\d\\d-\\d\\d\\d\\d\", \"XXXXX\", x) for x in data]\n",
    "data = [str(x).lower().replace('.',' ') for x in data]\n",
    "y_train = np.array(labels)\n",
    "\n",
    "# Unfortunately this cannot be used\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "vocab_data = np.unique([str(z).lower() for x in data for y in x.split('.') for z in y.split(' ') if z!= ''])\n",
    "max_len = len(vocab_data)\n",
    "vectorize_layer = TextVectorization(\n",
    "    max_tokens=max_len,\n",
    "    output_mode='binary')\n",
    "# Create the layer so that it can be used\n",
    "vectorize_layer.adapt(np.asarray(data))\n",
    "\n",
    "# Simplest Dense Layer\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.Input(shape=(1,), dtype=tf.string))\n",
    "model.add(vectorize_layer)\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy'\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "model.fit(np.array(data).reshape(-1,1), y_train, epochs=1, verbose=True)\n",
    "\n",
    "# Save the model\n",
    "tf.keras.models.save_model(model, \"pii_model_20210426\", overwrite=True, save_format='tf')\n",
    "model.save(\"pii_model_20210426_format1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i would like to close my account  my account number is xxxxx', 'hello i would like to close my account', 'my account needs to be closed', 'i need to close my account', 'can you close my account  my ssn is sssss6', 'my name is anant gupta and i would like to close my account', 'i need to open a new account  my ssn is sssss', 'i need to open a new account  do you need my ssn']\n",
      "[[1 0 0 0 0 1 0 0 0 0 1 1 1 0 0 0 0 1 0 0 0 0 1 1 1 0]\n",
      " [1 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 1 1 0 0]\n",
      " [1 0 0 1 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0]\n",
      " [1 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [1 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 1 0 0 0 1]\n",
      " [1 1 1 0 0 1 0 0 1 0 1 1 1 1 0 0 0 0 0 0 0 0 1 1 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 1 1 0 1 0 0 0]\n",
      " [1 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 1 0 1 1 0 0 1 0 0 1]]\n",
      "{'would': 23, 'like': 11, 'to': 22, 'close': 5, 'my': 12, 'account': 0, 'number': 17, 'is': 10, 'xxxxx': 24, 'hello': 9, 'needs': 15, 'be': 3, 'closed': 6, 'need': 14, 'can': 4, 'you': 25, 'ssn': 19, 'sssss6': 21, 'name': 13, 'anant': 1, 'gupta': 8, 'and': 2, 'open': 18, 'new': 16, 'sssss': 20, 'do': 7}\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_train_function.<locals>.train_function at 0x7f5840422320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:7 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f584038cc20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[[5 0]\n",
      " [0 3]]\n",
      "2021-04-30 14:11:57.244433: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "################################################\n",
    "### TRIAL 2\n",
    "################################################\n",
    "\n",
    "# Config\n",
    "#tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "# We will create our own dataset\n",
    "data = ['I would like to close my account. My account number is 000345-9876',\n",
    "       'Hello I would like to close my account',\n",
    "       'My account needs to be closed',\n",
    "       'I need to close my account',\n",
    "       'Can you close my account. My SSN is 345-456-88976',\n",
    "       'My name is Anant Gupta and I would like to close my account',\n",
    "       'I need to open a new account. My SSN is 607-089-4563',\n",
    "       'I need to open a new account. Do you need my SSN'\n",
    "       ]\n",
    "labels = [1,0,0,0,1,0,1,0]\n",
    "\n",
    "# We will now be converting SSN numbers to SSSSS, ACCOUNT numbers to XXXXX\n",
    "import re\n",
    "data = [re.sub(r\"\\d\\d\\d-\\d\\d\\d-\\d\\d\\d\\d\", \"SSSSS\", x) for x in data]\n",
    "data = [re.sub(r\"\\d\\d\\d\\d\\d\\d-\\d\\d\\d\\d\", \"XXXXX\", x) for x in data]\n",
    "data = [str(x).lower().replace('.',' ') for x in data]\n",
    "vocab_data = np.unique([str(z).lower() for x in data for y in x.split('.') for z in y.split(' ') if z!= ''])\n",
    "print(data)\n",
    "y_train = np.array(labels)\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(data)\n",
    "X = X.toarray()\n",
    "X[X>0]=1\n",
    "print(X)\n",
    "print(vectorizer.vocabulary_)\n",
    "\n",
    "# Simplest Dense Layer\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy'\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X.astype(np.float32), y_train, epochs=3000, verbose=False)\n",
    "predictions = model.predict(X.astype(np.float32)).reshape(-1)\n",
    "predictions = [1 if x>0.5 else 0 for x in predictions]\n",
    "print(confusion_matrix(y_train, predictions))\n",
    "\n",
    "# Save the model\n",
    "tf.keras.models.save_model(model, \"pii_model_20210426.h5\", overwrite=True, save_format='keras')\n",
    "\n",
    "!tensorflowjs_converter --input_format=keras --output_format=tfjs_layers_model pii_model_20210426.h5 pii_model_20210426_tfjs\n",
    "\n",
    "max_length = np.max(list(vectorizer.vocabulary_.values()))\n",
    "vocab_dict = dict((vectorizer.vocabulary_[i],i) for i in vectorizer.vocabulary_.keys())\n",
    "vocab=[]\n",
    "for i in range(max_length+1):\n",
    "    vocab.append(vocab_dict[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
